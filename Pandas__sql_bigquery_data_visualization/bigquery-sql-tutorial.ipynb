{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:39.505424Z",
     "iopub.status.busy": "2020-09-12T23:49:39.504838Z",
     "iopub.status.idle": "2020-09-12T23:49:39.507580Z",
     "shell.execute_reply": "2020-09-12T23:49:39.507127Z"
    },
    "papermill": {
     "duration": 0.015054,
     "end_time": "2020-09-12T23:49:39.507686",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.492632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006455,
     "end_time": "2020-09-12T23:49:39.520963",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.514508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Credits : #https://www.kaggle.com/rtatman/sql-scavenger-hunt-handbook/notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005959,
     "end_time": "2020-09-12T23:49:39.533383",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.527424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1- SQL is an important skill for every data scientist , it comes in third place as most popular software tool for data science. \n",
    "2-BigQuery is a Google Cloud product for storing and accessing very large databases very quickly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:39.551016Z",
     "iopub.status.busy": "2020-09-12T23:49:39.550222Z",
     "iopub.status.idle": "2020-09-12T23:49:39.558229Z",
     "shell.execute_reply": "2020-09-12T23:49:39.558862Z"
    },
    "papermill": {
     "duration": 0.019403,
     "end_time": "2020-09-12T23:49:39.559030",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.539627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Kaggle's public dataset BigQuery integration.\n"
     ]
    }
   ],
   "source": [
    "# import our bq_helper package\n",
    "import bq_helper\n",
    "# create a helper object for our bigquery dataset\n",
    "hacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n",
    "                                       dataset_name = \"hacker_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006378,
     "end_time": "2020-09-12T23:49:39.573531",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.567153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've created our helper object, we can get started actually interacting with the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00635,
     "end_time": "2020-09-12T23:49:39.586271",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.579921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we want to check out hte way the data is structured. we will look at the schema which is the description of how data is organized  within a dataset. \n",
    "we can use the BigQueryHelper.list_tables() method to list all the files in the hacker news dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:39.605978Z",
     "iopub.status.busy": "2020-09-12T23:49:39.605427Z",
     "iopub.status.idle": "2020-09-12T23:49:40.092022Z",
     "shell.execute_reply": "2020-09-12T23:49:40.091542Z"
    },
    "papermill": {
     "duration": 0.498801,
     "end_time": "2020-09-12T23:49:40.092144",
     "exception": false,
     "start_time": "2020-09-12T23:49:39.593343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comments', 'full', 'full_201510', 'stories']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a list of all the tables in the hacker_news dataset\n",
    "hacker_news.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:40.111422Z",
     "iopub.status.busy": "2020-09-12T23:49:40.110871Z",
     "iopub.status.idle": "2020-09-12T23:49:40.291328Z",
     "shell.execute_reply": "2020-09-12T23:49:40.291707Z"
    },
    "papermill": {
     "duration": 0.192634,
     "end_time": "2020-09-12T23:49:40.291867",
     "exception": false,
     "start_time": "2020-09-12T23:49:40.099233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>mode</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Story title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>url</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Story url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Story or comment text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dead</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Is dead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>The username of the item's author.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Story score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Unix time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Timestamp for the unix time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>type</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Type of details (comment, comment_ranking, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>The item's unique id.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>parent</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Parent comment ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>descendants</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Number of story or poll descendants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ranking</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Comment ranking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deleted</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>NULLABLE</td>\n",
       "      <td>Is deleted?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       type      mode  \\\n",
       "0         title     STRING  NULLABLE   \n",
       "1           url     STRING  NULLABLE   \n",
       "2          text     STRING  NULLABLE   \n",
       "3          dead    BOOLEAN  NULLABLE   \n",
       "4            by     STRING  NULLABLE   \n",
       "5         score    INTEGER  NULLABLE   \n",
       "6          time    INTEGER  NULLABLE   \n",
       "7     timestamp  TIMESTAMP  NULLABLE   \n",
       "8          type     STRING  NULLABLE   \n",
       "9            id    INTEGER  NULLABLE   \n",
       "10       parent    INTEGER  NULLABLE   \n",
       "11  descendants    INTEGER  NULLABLE   \n",
       "12      ranking    INTEGER  NULLABLE   \n",
       "13      deleted    BOOLEAN  NULLABLE   \n",
       "\n",
       "                                          description  \n",
       "0                                         Story title  \n",
       "1                                           Story url  \n",
       "2                               Story or comment text  \n",
       "3                                            Is dead?  \n",
       "4                  The username of the item's author.  \n",
       "5                                         Story score  \n",
       "6                                           Unix time  \n",
       "7                         Timestamp for the unix time  \n",
       "8   Type of details (comment, comment_ranking, pol...  \n",
       "9                               The item's unique id.  \n",
       "10                                  Parent comment ID  \n",
       "11                Number of story or poll descendants  \n",
       "12                                    Comment ranking  \n",
       "13                                        Is deleted?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hacker_news.table_schema(\"full\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0088,
     "end_time": "2020-09-12T23:49:40.308402",
     "exception": false,
     "start_time": "2020-09-12T23:49:40.299602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check the size of your query before you run it : \n",
    "BigQuery datasets are, true to their name, BIG. The biggest dataset we've got on Kaggle so far is 3 terabytes. Since the monthly quota for BigQuery queries is 5 terabytes, you can easily go past your 30-day quota by running just a couple of queries!\n",
    "\n",
    "What's a query? A query is small piece of SQL code that specifies what data would you like to scan from a databases, and how much of that data you would like returned. (Note that your quota is on data scanned, not the amount of data returned.)\n",
    "\n",
    "One way to help avoid this is to estimate how big your query will be before you actually execute it. You can do this with the BigQueryHelper.estimate_query_size() method. For the rest of this notebook, I'll be using an example query that finding the scores for every Hacker News post of the type \"job\". Let's see how much data it will scan if we actually ran it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:40.329440Z",
     "iopub.status.busy": "2020-09-12T23:49:40.328852Z",
     "iopub.status.idle": "2020-09-12T23:49:40.650437Z",
     "shell.execute_reply": "2020-09-12T23:49:40.649710Z"
    },
    "papermill": {
     "duration": 0.33458,
     "end_time": "2020-09-12T23:49:40.650590",
     "exception": false,
     "start_time": "2020-09-12T23:49:40.316010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22514757234603167"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this query looks in the full table in the hacker_news\n",
    "# dataset, then gets the score column from every row where \n",
    "# the type column has \"job\" in it.\n",
    "query = \"\"\"SELECT score\n",
    "            FROM `bigquery-public-data.hacker_news.full`\n",
    "            WHERE type = \"job\" \"\"\"\n",
    "\n",
    "# check how big this query will be\n",
    "hacker_news.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0079,
     "end_time": "2020-09-12T23:49:40.670501",
     "exception": false,
     "start_time": "2020-09-12T23:49:40.662601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Running this query will take around 225 MB. (The query size is returned in gigabytes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:40.691679Z",
     "iopub.status.busy": "2020-09-12T23:49:40.691143Z",
     "iopub.status.idle": "2020-09-12T23:49:41.097026Z",
     "shell.execute_reply": "2020-09-12T23:49:41.097499Z"
    },
    "papermill": {
     "duration": 0.419185,
     "end_time": "2020-09-12T23:49:41.097630",
     "exception": false,
     "start_time": "2020-09-12T23:49:40.678445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query cancelled; estimated size of 0.22514757234603167 exceeds limit of 0.1 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# only run this query if it's less than 100 MB\n",
    "hacker_news.query_to_pandas_safe(query, max_gb_scanned=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:41.117582Z",
     "iopub.status.busy": "2020-09-12T23:49:41.116759Z",
     "iopub.status.idle": "2020-09-12T23:49:41.119391Z",
     "shell.execute_reply": "2020-09-12T23:49:41.118821Z"
    },
    "papermill": {
     "duration": 0.013783,
     "end_time": "2020-09-12T23:49:41.119495",
     "exception": false,
     "start_time": "2020-09-12T23:49:41.105712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check out the scores of job postings (if the \n",
    "# query is smaller than 1 gig)\n",
    "#ob_post_scores = hacker_news.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T23:49:41.139727Z",
     "iopub.status.busy": "2020-09-12T23:49:41.138995Z",
     "iopub.status.idle": "2020-09-12T23:49:41.141804Z",
     "shell.execute_reply": "2020-09-12T23:49:41.141342Z"
    },
    "papermill": {
     "duration": 0.014012,
     "end_time": "2020-09-12T23:49:41.141899",
     "exception": false,
     "start_time": "2020-09-12T23:49:41.127887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since this has returned a dataframe, we can work with it as\n",
    "#we would any other dataframe. For example, we can get the mean of the column:\n",
    "\n",
    "# average score for job posts\n",
    "#job_post_scores.score.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5.603774,
   "end_time": "2020-09-12T23:49:41.255960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T23:49:35.652186",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
