{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.440694Z",
     "iopub.status.busy": "2020-08-19T14:58:33.439899Z",
     "iopub.status.idle": "2020-08-19T14:58:33.445413Z",
     "shell.execute_reply": "2020-08-19T14:58:33.444744Z"
    },
    "papermill": {
     "duration": 0.023926,
     "end_time": "2020-08-19T14:58:33.445573",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.421647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/test.csv\n",
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n"
     ]
    }
   ],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.471513Z",
     "iopub.status.busy": "2020-08-19T14:58:33.470818Z",
     "iopub.status.idle": "2020-08-19T14:58:33.476011Z",
     "shell.execute_reply": "2020-08-19T14:58:33.475318Z"
    },
    "papermill": {
     "duration": 0.020177,
     "end_time": "2020-08-19T14:58:33.476137",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.455960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.504506Z",
     "iopub.status.busy": "2020-08-19T14:58:33.503698Z",
     "iopub.status.idle": "2020-08-19T14:58:33.580743Z",
     "shell.execute_reply": "2020-08-19T14:58:33.581246Z"
    },
    "papermill": {
     "duration": 0.095349,
     "end_time": "2020-08-19T14:58:33.581424",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.486075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "target       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "test_data  =pd.read_csv('../input/nlp-getting-started/test.csv')\n",
    "train_data.head(10)\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.609787Z",
     "iopub.status.busy": "2020-08-19T14:58:33.608718Z",
     "iopub.status.idle": "2020-08-19T14:58:33.613800Z",
     "shell.execute_reply": "2020-08-19T14:58:33.613089Z"
    },
    "papermill": {
     "duration": 0.020959,
     "end_time": "2020-08-19T14:58:33.613930",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.592971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009876,
     "end_time": "2020-08-19T14:58:33.634362",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.624486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The regular expression above is meant to find any four digits at the beginning of a string, which suffices for our case. The above is a raw string (meaning that a backslash is no longer an escape character), which is standard practice with regular expressions.\n",
    "regex = r'^(\\d{4})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.691872Z",
     "iopub.status.busy": "2020-08-19T14:58:33.669612Z",
     "iopub.status.idle": "2020-08-19T14:58:33.890192Z",
     "shell.execute_reply": "2020-08-19T14:58:33.889445Z"
    },
    "papermill": {
     "duration": 0.245486,
     "end_time": "2020-08-19T14:58:33.890327",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.644841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \n",
       "0       1  our deeds are the reason of this earthquake ma...  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  all residents asked to shelter in place are be...  \n",
       "3       1   people receive wildfires evacuation orders in...  \n",
       "4       1  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return df\n",
    "data_clean = clean_text(train_data, 'text', 'text_clean')\n",
    "data_clean_test = clean_text(test_data,'text', 'text_clean')\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:33.920560Z",
     "iopub.status.busy": "2020-08-19T14:58:33.919754Z",
     "iopub.status.idle": "2020-08-19T14:58:37.040920Z",
     "shell.execute_reply": "2020-08-19T14:58:37.040231Z"
    },
    "papermill": {
     "duration": 3.139641,
     "end_time": "2020-08-19T14:58:37.041044",
     "exception": false,
     "start_time": "2020-08-19T14:58:33.901403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \n",
       "0       1       deeds reason earthquake may allah forgive us  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  residents asked shelter place notified officer...  \n",
       "3       1  people receive wildfires evacuation orders cal...  \n",
       "4       1  got sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:37.069412Z",
     "iopub.status.busy": "2020-08-19T14:58:37.068608Z",
     "iopub.status.idle": "2020-08-19T14:58:38.140403Z",
     "shell.execute_reply": "2020-08-19T14:58:38.141067Z"
    },
    "papermill": {
     "duration": 1.089507,
     "end_time": "2020-08-19T14:58:38.141277",
     "exception": false,
     "start_time": "2020-08-19T14:58:37.051770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \\\n",
       "0       1       deeds reason earthquake may allah forgive us   \n",
       "1       1              forest fire near la ronge sask canada   \n",
       "2       1  residents asked shelter place notified officer...   \n",
       "3       1  people receive wildfires evacuation orders cal...   \n",
       "4       1  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [deeds, reason, earthquake, may, allah, forgiv...  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [residents, asked, shelter, place, notified, o...  \n",
       "3  [people, receive, wildfires, evacuation, order...  \n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "data_clean['text_tokens'] = data_clean['text_clean'].apply(lambda x: word_tokenize(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:38.203663Z",
     "iopub.status.busy": "2020-08-19T14:58:38.182284Z",
     "iopub.status.idle": "2020-08-19T14:58:40.420556Z",
     "shell.execute_reply": "2020-08-19T14:58:40.419963Z"
    },
    "papermill": {
     "duration": 2.265235,
     "end_time": "2020-08-19T14:58:40.420692",
     "exception": false,
     "start_time": "2020-08-19T14:58:38.155457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>[peopl, receiv, wildfir, evacu, order, califor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \\\n",
       "0       1       deeds reason earthquake may allah forgive us   \n",
       "1       1              forest fire near la ronge sask canada   \n",
       "2       1  residents asked shelter place notified officer...   \n",
       "3       1  people receive wildfires evacuation orders cal...   \n",
       "4       1  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [deeds, reason, earthquake, may, allah, forgiv...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [residents, asked, shelter, place, notified, o...   \n",
       "3  [people, receive, wildfires, evacuation, order...   \n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                   text_clean_tokens  \n",
       "0  [deed, reason, earthquak, may, allah, forgiv, us]  \n",
       "1       [forest, fire, near, la, rong, sask, canada]  \n",
       "2  [resid, ask, shelter, place, notifi, offic, ev...  \n",
       "3  [peopl, receiv, wildfir, evacu, order, califor...  \n",
       "4  [got, sent, photo, rubi, alaska, smoke, wildfi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "def word_stemmer(text):\n",
    "    stem_text = [PorterStemmer().stem(i) for i in text]\n",
    "    return stem_text\n",
    "data_clean['text_clean_tokens'] = data_clean['text_tokens'].apply(lambda x: word_stemmer(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:40.450327Z",
     "iopub.status.busy": "2020-08-19T14:58:40.449656Z",
     "iopub.status.idle": "2020-08-19T14:58:42.870723Z",
     "shell.execute_reply": "2020-08-19T14:58:42.870030Z"
    },
    "papermill": {
     "duration": 2.438833,
     "end_time": "2020-08-19T14:58:42.870846",
     "exception": false,
     "start_time": "2020-08-19T14:58:40.432013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "      <td>[resident, asked, shelter, place, notified, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \\\n",
       "0       1       deeds reason earthquake may allah forgive us   \n",
       "1       1              forest fire near la ronge sask canada   \n",
       "2       1  residents asked shelter place notified officer...   \n",
       "3       1  people receive wildfires evacuation orders cal...   \n",
       "4       1  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [deeds, reason, earthquake, may, allah, forgiv...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [residents, asked, shelter, place, notified, o...   \n",
       "3  [people, receive, wildfires, evacuation, order...   \n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                   text_clean_tokens  \n",
       "0  [deed, reason, earthquake, may, allah, forgive...  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [resident, asked, shelter, place, notified, of...  \n",
       "3  [people, receive, wildfire, evacuation, order,...  \n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "data_clean['text_clean_tokens'] = data_clean['text_tokens'].apply(lambda x: word_lemmatizer(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:42.918103Z",
     "iopub.status.busy": "2020-08-19T14:58:42.910593Z",
     "iopub.status.idle": "2020-08-19T14:58:42.921615Z",
     "shell.execute_reply": "2020-08-19T14:58:42.920854Z"
    },
    "papermill": {
     "duration": 0.039439,
     "end_time": "2020-08-19T14:58:42.921746",
     "exception": false,
     "start_time": "2020-08-19T14:58:42.882307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:42.962855Z",
     "iopub.status.busy": "2020-08-19T14:58:42.961810Z",
     "iopub.status.idle": "2020-08-19T14:58:42.967360Z",
     "shell.execute_reply": "2020-08-19T14:58:42.966666Z"
    },
    "papermill": {
     "duration": 0.033992,
     "end_time": "2020-08-19T14:58:42.967490",
     "exception": false,
     "start_time": "2020-08-19T14:58:42.933498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.028631Z",
     "iopub.status.busy": "2020-08-19T14:58:43.023331Z",
     "iopub.status.idle": "2020-08-19T14:58:43.035607Z",
     "shell.execute_reply": "2020-08-19T14:58:43.034863Z"
    },
    "papermill": {
     "duration": 0.056385,
     "end_time": "2020-08-19T14:58:43.035744",
     "exception": false,
     "start_time": "2020-08-19T14:58:42.979359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.097193Z",
     "iopub.status.busy": "2020-08-19T14:58:43.091510Z",
     "iopub.status.idle": "2020-08-19T14:58:43.100237Z",
     "shell.execute_reply": "2020-08-19T14:58:43.100739Z"
    },
    "papermill": {
     "duration": 0.05296,
     "end_time": "2020-08-19T14:58:43.100902",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.047942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.130819Z",
     "iopub.status.busy": "2020-08-19T14:58:43.129820Z",
     "iopub.status.idle": "2020-08-19T14:58:43.134077Z",
     "shell.execute_reply": "2020-08-19T14:58:43.133519Z"
    },
    "papermill": {
     "duration": 0.021423,
     "end_time": "2020-08-19T14:58:43.134219",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.112796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip3 install pyspellchecker==20.2.2\\nfrom spellchecker import SpellChecker\\n\\nspell = SpellChecker()\\ndef correct_spellings(text):\\n    corrected_text = []\\n    misspelled_words = spell.unknown(text.split())\\n    for word in text.split():\\n        if word in misspelled_words:\\n            corrected_text.append(spell.correction(word))\\n        else:\\n            corrected_text.append(word)\\n    return \" \".join(corrected_text)\\n\\ndata_clean[\\'text_clean\\'] = data_clean[\\'text_clean\\'].apply(lambda x: correct_spellings(x))'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip3 install pyspellchecker==20.2.2\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: correct_spellings(x))\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.166561Z",
     "iopub.status.busy": "2020-08-19T14:58:43.165828Z",
     "iopub.status.idle": "2020-08-19T14:58:43.248973Z",
     "shell.execute_reply": "2020-08-19T14:58:43.248205Z"
    },
    "papermill": {
     "duration": 0.102238,
     "end_time": "2020-08-19T14:58:43.249103",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.146865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.310117Z",
     "iopub.status.busy": "2020-08-19T14:58:43.287121Z",
     "iopub.status.idle": "2020-08-19T14:58:43.353396Z",
     "shell.execute_reply": "2020-08-19T14:58:43.352675Z"
    },
    "papermill": {
     "duration": 0.092576,
     "end_time": "2020-08-19T14:58:43.353523",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.260947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(data_clean['text_clean']).split()).value_counts()[:10]\n",
    "\n",
    "freq = list(freq.index)\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.385297Z",
     "iopub.status.busy": "2020-08-19T14:58:43.384542Z",
     "iopub.status.idle": "2020-08-19T14:58:43.390252Z",
     "shell.execute_reply": "2020-08-19T14:58:43.389417Z"
    },
    "papermill": {
     "duration": 0.024412,
     "end_time": "2020-08-19T14:58:43.390415",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.366003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data_clean['text_clean'], \n",
    "                   \n",
    "                                                    data_clean['target'], \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.422793Z",
     "iopub.status.busy": "2020-08-19T14:58:43.421867Z",
     "iopub.status.idle": "2020-08-19T14:58:43.425649Z",
     "shell.execute_reply": "2020-08-19T14:58:43.424902Z"
    },
    "papermill": {
     "duration": 0.022384,
     "end_time": "2020-08-19T14:58:43.425788",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.403404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                       ngram_range=(1,1),\n",
    "                       max_df=1.0,\n",
    "                       min_df=10,\n",
    "                       max_features=500,\n",
    "                       norm='l2',\n",
    "                       sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.479843Z",
     "iopub.status.busy": "2020-08-19T14:58:43.464014Z",
     "iopub.status.idle": "2020-08-19T14:58:43.658986Z",
     "shell.execute_reply": "2020-08-19T14:58:43.659898Z"
    },
    "papermill": {
     "duration": 0.222097,
     "end_time": "2020-08-19T14:58:43.660178",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.438081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 500)\n"
     ]
    }
   ],
   "source": [
    "train_features = tfidf.fit_transform(X_train).toarray()\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.704713Z",
     "iopub.status.busy": "2020-08-19T14:58:43.693913Z",
     "iopub.status.idle": "2020-08-19T14:58:43.737625Z",
     "shell.execute_reply": "2020-08-19T14:58:43.736976Z"
    },
    "papermill": {
     "duration": 0.064437,
     "end_time": "2020-08-19T14:58:43.737756",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.673319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 500)\n"
     ]
    }
   ],
   "source": [
    "test_features = tfidf.transform(X_test).toarray()\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.768345Z",
     "iopub.status.busy": "2020-08-19T14:58:43.767596Z",
     "iopub.status.idle": "2020-08-19T14:58:43.770453Z",
     "shell.execute_reply": "2020-08-19T14:58:43.770942Z"
    },
    "papermill": {
     "duration": 0.020766,
     "end_time": "2020-08-19T14:58:43.771108",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.750342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = Y_train\n",
    "test_labels = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.800946Z",
     "iopub.status.busy": "2020-08-19T14:58:43.800267Z",
     "iopub.status.idle": "2020-08-19T14:58:43.809905Z",
     "shell.execute_reply": "2020-08-19T14:58:43.809222Z"
    },
    "papermill": {
     "duration": 0.026526,
     "end_time": "2020-08-19T14:58:43.810026",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.783500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.840190Z",
     "iopub.status.busy": "2020-08-19T14:58:43.839347Z",
     "iopub.status.idle": "2020-08-19T14:58:43.842861Z",
     "shell.execute_reply": "2020-08-19T14:58:43.843378Z"
    },
    "papermill": {
     "duration": 0.020958,
     "end_time": "2020-08-19T14:58:43.843554",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.822596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.874440Z",
     "iopub.status.busy": "2020-08-19T14:58:43.873710Z",
     "iopub.status.idle": "2020-08-19T14:58:43.933366Z",
     "shell.execute_reply": "2020-08-19T14:58:43.932592Z"
    },
    "papermill": {
     "duration": 0.076848,
     "end_time": "2020-08-19T14:58:43.933526",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.856678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:43.968752Z",
     "iopub.status.busy": "2020-08-19T14:58:43.967690Z",
     "iopub.status.idle": "2020-08-19T14:58:43.974649Z",
     "shell.execute_reply": "2020-08-19T14:58:43.973981Z"
    },
    "papermill": {
     "duration": 0.024863,
     "end_time": "2020-08-19T14:58:43.974785",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.949922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnb_prediction = mnb_classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.006857Z",
     "iopub.status.busy": "2020-08-19T14:58:44.005182Z",
     "iopub.status.idle": "2020-08-19T14:58:44.017219Z",
     "shell.execute_reply": "2020-08-19T14:58:44.017902Z"
    },
    "papermill": {
     "duration": 0.030734,
     "end_time": "2020-08-19T14:58:44.018114",
     "exception": false,
     "start_time": "2020-08-19T14:58:43.987380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786863711001642\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = accuracy_score(train_labels, mnb_classifier.predict(train_features))\n",
    "print(training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.051327Z",
     "iopub.status.busy": "2020-08-19T14:58:44.050251Z",
     "iopub.status.idle": "2020-08-19T14:58:44.056875Z",
     "shell.execute_reply": "2020-08-19T14:58:44.056308Z"
    },
    "papermill": {
     "duration": 0.025154,
     "end_time": "2020-08-19T14:58:44.056996",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.031842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662508207485227\n"
     ]
    }
   ],
   "source": [
    "testing_accuracy = accuracy_score(test_labels, mnb_prediction)\n",
    "print(testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.090200Z",
     "iopub.status.busy": "2020-08-19T14:58:44.089290Z",
     "iopub.status.idle": "2020-08-19T14:58:44.101747Z",
     "shell.execute_reply": "2020-08-19T14:58:44.100739Z"
    },
    "papermill": {
     "duration": 0.031242,
     "end_time": "2020-08-19T14:58:44.101920",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.070678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       861\n",
      "           1       0.78      0.64      0.70       662\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.75      0.76      1523\n",
      "weighted avg       0.77      0.77      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, mnb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.012433,
     "end_time": "2020-08-19T14:58:44.128026",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.115593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.159827Z",
     "iopub.status.busy": "2020-08-19T14:58:44.158845Z",
     "iopub.status.idle": "2020-08-19T14:58:44.167444Z",
     "shell.execute_reply": "2020-08-19T14:58:44.166519Z"
    },
    "papermill": {
     "duration": 0.026691,
     "end_time": "2020-08-19T14:58:44.167618",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.140927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[743 118]\n",
      " [238 424]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, mnb_prediction)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.247807Z",
     "iopub.status.busy": "2020-08-19T14:58:44.236793Z",
     "iopub.status.idle": "2020-08-19T14:58:44.303841Z",
     "shell.execute_reply": "2020-08-19T14:58:44.303143Z"
    },
    "papermill": {
     "duration": 0.122636,
     "end_time": "2020-08-19T14:58:44.303987",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.181351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_vectorizer =tfidf.transform( data_clean_test['text_clean']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.336435Z",
     "iopub.status.busy": "2020-08-19T14:58:44.335460Z",
     "iopub.status.idle": "2020-08-19T14:58:44.340339Z",
     "shell.execute_reply": "2020-08-19T14:58:44.339693Z"
    },
    "papermill": {
     "duration": 0.023161,
     "end_time": "2020-08-19T14:58:44.340461",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.317300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.373182Z",
     "iopub.status.busy": "2020-08-19T14:58:44.372462Z",
     "iopub.status.idle": "2020-08-19T14:58:44.380017Z",
     "shell.execute_reply": "2020-08-19T14:58:44.380536Z"
    },
    "papermill": {
     "duration": 0.025947,
     "end_time": "2020-08-19T14:58:44.380713",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.354766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions = mnb_classifier.predict(test_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.414615Z",
     "iopub.status.busy": "2020-08-19T14:58:44.413542Z",
     "iopub.status.idle": "2020-08-19T14:58:44.418054Z",
     "shell.execute_reply": "2020-08-19T14:58:44.418582Z"
    },
    "papermill": {
     "duration": 0.02367,
     "end_time": "2020-08-19T14:58:44.418751",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.395081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.455084Z",
     "iopub.status.busy": "2020-08-19T14:58:44.454374Z",
     "iopub.status.idle": "2020-08-19T14:58:44.458040Z",
     "shell.execute_reply": "2020-08-19T14:58:44.457371Z"
    },
    "papermill": {
     "duration": 0.025186,
     "end_time": "2020-08-19T14:58:44.458182",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.432996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.497107Z",
     "iopub.status.busy": "2020-08-19T14:58:44.496432Z",
     "iopub.status.idle": "2020-08-19T14:58:44.499846Z",
     "shell.execute_reply": "2020-08-19T14:58:44.499292Z"
    },
    "papermill": {
     "duration": 0.027882,
     "end_time": "2020-08-19T14:58:44.499980",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.472098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df['id'] = data_clean_test['id']\n",
    "submission_df['target'] = final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.540020Z",
     "iopub.status.busy": "2020-08-19T14:58:44.536953Z",
     "iopub.status.idle": "2020-08-19T14:58:44.544835Z",
     "shell.execute_reply": "2020-08-19T14:58:44.544177Z"
    },
    "papermill": {
     "duration": 0.03143,
     "end_time": "2020-08-19T14:58:44.544954",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.513524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       0\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       0\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.581580Z",
     "iopub.status.busy": "2020-08-19T14:58:44.580692Z",
     "iopub.status.idle": "2020-08-19T14:58:44.585373Z",
     "shell.execute_reply": "2020-08-19T14:58:44.584693Z"
    },
    "papermill": {
     "duration": 0.026392,
     "end_time": "2020-08-19T14:58:44.585500",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.559108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2128\n",
       "1    1135\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-19T14:58:44.618269Z",
     "iopub.status.busy": "2020-08-19T14:58:44.617281Z",
     "iopub.status.idle": "2020-08-19T14:58:44.740995Z",
     "shell.execute_reply": "2020-08-19T14:58:44.740358Z"
    },
    "papermill": {
     "duration": 0.142059,
     "end_time": "2020-08-19T14:58:44.741129",
     "exception": false,
     "start_time": "2020-08-19T14:58:44.599070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = submission_df.to_csv('Result.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 16.713053,
   "end_time": "2020-08-19T14:58:44.863629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-19T14:58:28.150576",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
